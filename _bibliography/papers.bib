---
---

@inproceedings{sasse-etal-2025-making,
    title = "Making {FETCH}! Happen: Finding Emergent Dog Whistles Through Common Habitats",
    author = "Sasse, Kuleen  and
      Aguirre, Carlos Alejandro  and
      Cachola, Isabel  and
      Levy, Sharon  and
      Dredze, Mark",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.284/",
    doi = "10.18653/v1/2025.acl-long.284",
    pages = "5687--5709",
    ISBN = "979-8-89176-251-0",
    abstract = "Dog whistles are coded expressions with dual meanings: one intended for the general public (outgroup) and another that conveys a specific message to an intended audience (ingroup). Often, these expressions are used to convey controversial political opinions while maintaining plausible deniability and slip by content moderation filters. Identification of dog whistles relies on curated lexicons, which have trouble keeping up to date. We introduce FETCH!, a task for finding novel dog whistles in massive social media corpora. We find that state-of-the-art systems fail to achieve meaningful results across three distinct social media case studies. We present EarShot, a strong baseline system that combines the strengths of vector databases and Large Language Models (LLMs) to efficiently and effectively identify new dog whistles."
}


@misc{sasse2025controllablehybridcaptionerimproved,
      title={Controllable Hybrid Captioner for Improved Long-form Video Understanding}, 
      author={Kuleen Sasse and Efsun Sarioglu Kayi and Arun Reddy},
      year={2025},
      eprint={2507.17047},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.17047}, 
}

@inproceedings{sasse-etal-2023-burst,
    title = "To Burst or Not to Burst: Generating and Quantifying Improbable Text",
    author = "Sasse, Kuleen  and
      Sarioglu Kayi, Efsun  and
      Barham, Samuel  and
      Staley, Edward",
    editor = "Gehrmann, Sebastian  and
      Wang, Alex  and
      Sedoc, Jo{\~a}o  and
      Clark, Elizabeth  and
      Dhole, Kaustubh  and
      Chandu, Khyathi Raghavi  and
      Santus, Enrico  and
      Sedghamiz, Hooman",
    booktitle = "Proceedings of the Third Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.gem-1.24/",
    pages = "289--309",
    abstract = "While large language models (LLMs) are extremely capable at text generation, their outputs are still distinguishable from human-authored text. We explore this separation across many metrics over text, many sampling techniques, many types of text data, and across two popular LLMs, LLaMA and Vicuna. Along the way, we introduce a new metric, recoverability, to highlight differences between human and machine text; and we propose a new sampling technique, burst sampling, designed to close this gap. We find that LLaMA and Vicuna have distinct distributions under many of the metrics, and that this influences our results: Recoverability separates real from fake text better than any other metric when using LLaMA. When using Vicuna, burst sampling produces text which is distributionally closer to real text compared to other sampling techniques."
}

@misc{sasse2024diseaseentityrecognitionnormalization,
      title={Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions}, 
      author={Kuleen Sasse and Shinjitha Vadlakonda and Richard E. Kennedy and John D. Osborne},
      year={2024},
      eprint={2410.07951},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.07951}, 
}

@misc{sasse2025debiasaebenchmarkingmitigatingvisionlanguage,
      title={debiaSAE: Benchmarking and Mitigating Vision-Language Model Bias}, 
      author={Kuleen Sasse and Shan Chen and Jackson Pond and Danielle Bitterman and John Osborne},
      year={2025},
      eprint={2410.13146},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.13146}, 
}

@misc{gallifant2025sparseautoencoderfeaturesclassifications,
      title={Sparse Autoencoder Features for Classifications and Transferability}, 
      author={Jack Gallifant and Shan Chen and Kuleen Sasse and Hugo Aerts and Thomas Hartvigsen and Danielle S. Bitterman},
      year={2025},
      eprint={2502.11367},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.11367}, 
}

@misc{chen2024waittylenolacetaminopheninvestigating,
      title={Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation}, 
      author={Shan Chen and Mingye Gao and Kuleen Sasse and Thomas Hartvigsen and Brian Anthony and Lizhou Fan and Hugo Aerts and Jack Gallifant and Danielle Bitterman},
      year={2024},
      eprint={2409.20385},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.20385}, 
}

@inproceedings{aguirre-etal-2024-selecting,
    title = "Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models",
    author = "Aguirre, Carlos Alejandro  and
      Sasse, Kuleen  and
      Cachola, Isabel Alyssa  and
      Dredze, Mark",
    editor = "Dementieva, Daryna  and
      Ignat, Oana  and
      Jin, Zhijing  and
      Mihalcea, Rada  and
      Piatti, Giorgio  and
      Tetreault, Joel  and
      Wilson, Steven  and
      Zhao, Jieyu",
    booktitle = "Proceedings of the Third Workshop on NLP for Positive Impact",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.nlp4pi-1.4/",
    doi = "10.18653/v1/2024.nlp4pi-1.4",
    pages = "50--67",
    abstract = "Recently, work in NLP has shifted to few-shot (in-context) learning, with large language models (LLMs) performing well across a range of tasks. However, while fairness evaluations have become a standard for supervised methods, little is known about the fairness of LLMs as prediction systems. Further, common standard methods for fairness involve access to model weights or are applied during finetuning, which are not applicable in few-shot learning. Do LLMs exhibit prediction biases when used for standard NLP tasks?In this work, we analyze the effect of shots, which directly affect the performance of models, on the fairness of LLMs as NLP classification systems. We consider how different shot selection strategies, both existing and new demographically sensitive methods, affect model fairness across three standard fairness datasets. We find that overall the performance of LLMs is not indicative of their fairness, and there is not a single method that fits all scenarios. In light of these facts, we discuss how future work can include LLM fairness in evaluations."
}

@article{10.1371/journal.pone.0301488,
    doi = {10.1371/journal.pone.0301488},
    author = {Sasse, Kuleen AND Mahabir, Ron AND Gkountouna, Olga AND Crooks, Andrew AND Croitoru, Arie},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Understanding the determinants of vaccine hesitancy in the United States: A comparison of social surveys and social media},
    year = {2024},
    month = {06},
    volume = {19},
    url = {https://doi.org/10.1371/journal.pone.0301488},
    pages = {1-30},
    abstract = {The COVID-19 pandemic prompted governments worldwide to implement a range of containment measures, including mass gathering restrictions, social distancing, and school closures. Despite these efforts, vaccines continue to be the safest and most effective means of combating such viruses. Yet, vaccine hesitancy persists, posing a significant public health concern, particularly with the emergence of new COVID-19 variants. To effectively address this issue, timely data is crucial for understanding the various factors contributing to vaccine hesitancy. While previous research has largely relied on traditional surveys for this information, recent sources of data, such as social media, have gained attention. However, the potential of social media data as a reliable proxy for information on population hesitancy, especially when compared with survey data, remains underexplored. This paper aims to bridge this gap. Our approach uses social, demographic, and economic data to predict vaccine hesitancy levels in the ten most populous US metropolitan areas. We employ machine learning algorithms to compare a set of baseline models that contain only these variables with models that incorporate survey data and social media data separately. Our results show that XGBoost algorithm consistently outperforms Random Forest and Linear Regression, with marginal differences between Random Forest and XGBoost. This was especially the case with models that incorporate survey or social media data, thus highlighting the promise of the latter data as a complementary information source. Results also reveal variations in influential variables across the five hesitancy classes, such as age, ethnicity, occupation, and political inclination. Further, the application of models to different MSAs yields mixed results, emphasizing the uniqueness of communities and the need for complementary data approaches. In summary, this study underscores social media dataâ€™s potential for understanding vaccine hesitancy, emphasizes the importance of tailoring interventions to specific communities, and suggests the value of combining different data sources.},
    number = {6},

}